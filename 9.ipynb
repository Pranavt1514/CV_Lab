{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ace510-8613-4933-8b0e-3f9e72ae5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629639f7-c7cc-4d29-8829-4d727d06f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693a8e90-4bb5-497c-9b39-843e16f09fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask: Optional[torch.Tensor]=None, dropout: Optional[nn.Module]=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        # mask: 1 for allowed positions, 0 for masked\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d718ce08-4542-49e0-a182-856a3948889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # same mask applied to all heads\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
    "                             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear\n",
    "        x = x.transpose(1,2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6776caad-4937-408b-8de5-6aeb4b814fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6fb29d-cc62-46b2-9c01-2ac16b88cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a523c9d7-0aa9-453e-990b-d23302413248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6657df2-ca0d-4ea4-adf0-61ad1ced2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"A residual connection followed by layer norm.\"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"\"\"Apply residual connection to any sublayer with the same size.\"\"\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab6cd7f-0e6a-453c-88cb-0084170b8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc6ce5f-d7cd-4fe3-8597-9fd4e5a173a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb6a5c44-aa12-42bf-b5a0-f59aa230dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c137f336-7d62-47bd-af53-dacdcb5c7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee6df28-ef22-4294-a210-bc4c4c359264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, N=6, h=8, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_embed = nn.Sequential(nn.Embedding(src_vocab, d_model), PositionalEncoding(d_model, dropout))\n",
    "        self.tgt_embed = nn.Sequential(nn.Embedding(tgt_vocab, d_model), PositionalEncoding(d_model, dropout))\n",
    "\n",
    "        attn = MultiHeadedAttention(h, d_model, dropout)\n",
    "        ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        encoder_layer = EncoderLayer(d_model, copy.deepcopy(attn), copy.deepcopy(ff), dropout)\n",
    "        decoder_layer = DecoderLayer(d_model, copy.deepcopy(attn), copy.deepcopy(attn), copy.deepcopy(ff), dropout)\n",
    "\n",
    "        self.encoder = Encoder(encoder_layer, N)\n",
    "        self.decoder = Decoder(decoder_layer, N)\n",
    "        self.out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "        # Initialize parameters\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        dec = self.decode(memory, src_mask, tgt, tgt_mask)\n",
    "        return self.out(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eaec819-e92d-4426-b9f1-4fd4e4ac4635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"\"\"Mask out subsequent positions.\"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return subsequent == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d201465-66c7-4987-84c0-d12e77b47f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_std_mask(tgt, pad):\n",
    "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask)\n",
    "    return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e53d6bd-0349-4aa2-a18d-8903638ef878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyDataset(Dataset):\n",
    "    def __init__(self, vocab_size=11, seq_len=10, size=10000, pad=0):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.size = size\n",
    "        self.pad = pad\n",
    "        self.data = [self._sample() for _ in range(size)]\n",
    "\n",
    "    def _sample(self):\n",
    "        # random sequence excluding pad (0) and special tokens\n",
    "        seq = [random.randint(1, self.vocab_size-1) for _ in range(self.seq_len)]\n",
    "        return torch.tensor(seq, dtype=torch.long), torch.tensor(seq, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3116720-61b6-4ea5-ac61-dff8132e1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        # x: (batch*seq_len, vocab) - log probabilities assumed\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        return self.criterion(x, true_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad412ed4-6a71-45ea-8387-8416dda0e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transformer():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    vocab_size = 12\n",
    "    pad_idx = 0\n",
    "    seq_len = 8\n",
    "\n",
    "    model = Transformer(src_vocab=vocab_size, tgt_vocab=vocab_size, d_model=128, N=3, h=4, d_ff=256, dropout=0.1).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    dataset = CopyDataset(vocab_size=vocab_size, seq_len=seq_len, size=5000, pad=pad_idx)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, 6):\n",
    "        total_loss = 0\n",
    "        for i, (src, tgt) in enumerate(loader):\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            # prepare input and output\n",
    "            tgt_input = torch.cat([torch.full((tgt.size(0),1), 1, dtype=torch.long, device=device), tgt[:,:-1]], dim=1)\n",
    "            src_mask = (src != pad_idx).unsqueeze(-2)\n",
    "            tgt_mask = make_std_mask(tgt_input, pad_idx).to(device)\n",
    "\n",
    "            out = model(src, tgt_input, src_mask.to(device), tgt_mask)\n",
    "            loss = criterion(out.view(-1, out.size(-1)), tgt.view(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch} Loss: {total_loss/len(dataset):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    sample_src, sample_tgt = dataset[0]\n",
    "    src = sample_src.unsqueeze(0).to(device)\n",
    "    generated = [1]\n",
    "    for _ in range(seq_len):\n",
    "        tgt_in = torch.tensor(generated, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        tgt_mask = make_std_mask(tgt_in, pad_idx).to(device)\n",
    "        out = model(src, tgt_in, (src!=pad_idx).unsqueeze(-2).to(device), tgt_mask)\n",
    "        next_word = out.argmax(dim=-1)[0, -1].item()\n",
    "        generated.append(next_word)\n",
    "    print(\"Source:\", sample_src.tolist())\n",
    "    print(\"Target:\", sample_tgt.tolist())\n",
    "    print(\"Generated:\", generated[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89740bad-045a-443e-a3c9-d4cacf000633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0378\n",
      "Epoch 2 Loss: 0.0165\n",
      "Epoch 3 Loss: 0.0027\n",
      "Epoch 4 Loss: 0.0016\n",
      "Epoch 5 Loss: 0.0009\n",
      "Source: [1, 9, 4, 5, 10, 3, 3, 7]\n",
      "Target: [1, 9, 4, 5, 10, 3, 3, 7]\n",
      "Generated: [1, 9, 4, 5, 10, 3, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "run_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744272e-e40c-4032-b6a3-a603562e4b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
